% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model.selection.R
\name{csslr.model.selection}
\alias{csslr.model.selection}
\title{Routine to run automated logistic regression model selection}
\usage{
csslr.model.selection(
  response,
  DT.data,
  selectionVariables,
  selectionMode = "AUC_or_MSE",
  pCoeff = 0.05,
  vifCrit = 5,
  pCalib = 0.5,
  pAUC = 0.05,
  pMSE = 0.05,
  pAUCTrim = 0.025,
  pMSETrim = 0.025,
  pAUCEquiv = 0.1,
  pMSEEquiv = 0.1,
  applyAIC = TRUE,
  applyBIC = TRUE,
  panelDataIdentifier = "",
  maxSelectionSteps = 10,
  maxEquivalentModels = 10,
  skipTrimming = FALSE,
  debugLevel = 0
)
}
\arguments{
\item{response}{Column name of the response variable contained in DT.data}

\item{DT.data}{Data set containing the response variable and all independent variables}

\item{selectionVariables}{List of variable in DT.data from which the logistic regression model
should be built}

\item{selectionMode}{Variables that controls when a model should be considered as an
improvement over a reference model: Either AUC and MSE have to show an improvement ('AUC_and_MSE')
or, alternatively, one has to show an improvement and the other no deterioration ('AUC_or_MSE')}

\item{pCoeff}{When testing for significance of coefficients, the p-value has to be below
pCoeff to consider a model as improved}

\item{vifCrit}{When computing variance inflation factors, all VIFs have to be below vifCrit
to consider a model as improved}

\item{pCalib}{When performing the Spiegelhalter calibration test, the p-value has to be larger
than pCalib to consider a model as improved}

\item{pAUC}{When testing for difference in AUC after including a variable, the p-value has to be
below pAUC to consider the extended model as improved}

\item{pMSE}{When testing for difference in MSE after including a variable, the p-value has to be
below pMSE to consider the extended model as improved}

\item{pAUCTrim}{When removing a variable, AUC is considered as improved if its value has increased and
the p-value of the AUC-test is below pAUCTrim}

\item{pMSETrim}{When removing a variable, MSE is considered as improved if its value has decreased and
the p-value of the MSE-test is below pMSETrim}

\item{pAUCEquiv}{When comparing two models, they are considered as equivalent with respect to AUC
when the p-value of the AUC-test is above pAUCEquiv}

\item{pMSEEquiv}{When comparing two models, they are considered as equivalent with respect to MSE
when the p-value of the MSE-test is above pMSEEquiv}

\item{applyAIC}{Apply the AIC criterion when deciding about model improvement (TRUE); ignore AIC (FALSE)}

\item{applyBIC}{Apply the BIC criterion when deciding about model improvement (TRUE); ignore BIC (FALSE)}

\item{panelDataIdentifier}{In panel data sets, multiple data sets are recorded at different points in time
but belong to the same entity, e.g., a company or a person. The panelDataIdentifier is the ID / Name that
identifies the entity}

\item{maxSelectionSteps}{Maximum number of selection steps performed if no termination criterion is met earlier}

\item{maxEquivalentModels}{If p-values are set rather high, the number of models selected might become very
high; to keep the outcome and computational time manageable, a maximum number of equivalent models selected
in each selection step can be capped by this parameter}

\item{skipTrimming}{Model trimming is the least important step in the model selection but might
consume a significant proportion of computational time especially for large data sets. This
parameter allows turning trimming off if it is TRUE and running trimming if it is FALSE}

\item{debugLevel}{Parameter that controls printing on screen when running the selection algorithm (0: No output
on screen; 1: Limited output showing the current progress step; 2: Detailed output of the model currently analyzed)}
}
\value{
A list containing three elements: A list of leading model(s), a second list
of models that are equivalent to the leading models (might be empty), an extensive
list containing data.tables reporting every selection step and it outcome
}
\description{
This function implements the core CSSLR variable selection algorithm which
is described in Engelmann B., Comprehensive Stepwise Selection for Logistic Regression
}
\examples{

set.seed(123)
DT.data <- data.table(Response = c(rep(0,100),rep(1,100)))
DT.data[Response == 0, Strong1 := rnorm(100, 1.0, 1.0)]
DT.data[Response == 1, Strong1 := rnorm(100, -1.0, 1.0)]
DT.data[Response == 0, Strong2 := rnorm(100, 1.0, 1.0)]
DT.data[Response == 1, Strong2 := rnorm(100, -1.0, 1.0)]
DT.data[Response == 0, Weak1 := rnorm(100, 0.5, 1.0)]
DT.data[Response == 1, Weak1 := rnorm(100, -0.5, 1.0)]
DT.data[Response == 0, Weak2 := rnorm(100, 0.5, 1.0)]
DT.data[Response == 1, Weak2 := rnorm(100, -0.5, 1.0)]
DT.data[Response == 0, Random1 := rnorm(100, 0.0, 1.0)]
DT.data[Response == 1, Random1 := rnorm(100, 0.0, 1.0)]
DT.data[Response == 0, Random2 := rnorm(100, 0.0, 1.0)]
DT.data[Response == 1, Random2 := rnorm(100, 0.0, 1.0)]

selectionVariables <- names(DT.data)[-1]
SelectionOutput <- csslr.model.selection('Response', DT.data, selectionVariables)

# Print the selected leading model(s)
print(SelectionOutput[['ModelsLeading']])

# Print all equivalent models (may include more than the leading models)
print(SelectionOutput[['Equivalent']])

}
