% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stats.calib.test.R
\name{csslr.stats.calib.test}
\alias{csslr.stats.calib.test}
\title{Redelmeier test on comparing the MSE of two different probability forecasts}
\usage{
csslr.stats.calib.test(indicators, probabilities1, probabilities2)
}
\arguments{
\item{indicators}{Vector of 0/1 values where 0 is a "good" observation
and "1" models a bad observation}

\item{probabilities1}{Probability forecasts of Model 1}

\item{probabilities2}{Probability forecasts of Model 2}
}
\value{
List with MSE, expected MSE for both probability forecasts together
with test statistic and p-value of the Redelmeier et al test
}
\description{
This routine implements the Redelmeier et al (Redelmeier D. A.,
Bloch D. A. & Hickam D. H. (1991), Assessing predictive accuracy: How to compare
Brier scores’, Journal of Clinical Epidemiology 44(11), 1141–1146) test on the
difference of MSE for two probability forecasts. The null hypothesis is that the
MSE of both probability forecasts is equal
}
